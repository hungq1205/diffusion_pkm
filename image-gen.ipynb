{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 10646,
     "status": "ok",
     "timestamp": 1726733111024,
     "user": {
      "displayName": "Hung Quang",
      "userId": "12748928474967436233"
     },
     "user_tz": -420
    },
    "id": "09lvcQtbVf50"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import PIL\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2479,
     "status": "ok",
     "timestamp": 1726733126511,
     "user": {
      "displayName": "Hung Quang",
      "userId": "12748928474967436233"
     },
     "user_tz": -420
    },
    "id": "rk2BfZJ8hPmS",
    "outputId": "c58a38cf-3267-4b22-9492-57f9980cdfcd"
   },
   "outputs": [],
   "source": [
    "img_path = \"./dataset/pkm\"\n",
    "random_img_path = \"./dataset/pkm-random\"\n",
    "checkpoint_path = \"./checkpoint/image_gen.pth\"\n",
    "# os.remove('./data/images/indeedee-female.png') # corrupted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1726733127209,
     "user": {
      "displayName": "Hung Quang",
      "userId": "12748928474967436233"
     },
     "user_tz": -420
    },
    "id": "3nDQWlHO04Rd"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1726733127209,
     "user": {
      "displayName": "Hung Quang",
      "userId": "12748928474967436233"
     },
     "user_tz": -420
    },
    "id": "0S-jNp1MZo7t"
   },
   "outputs": [],
   "source": [
    "def to_pil_image(x):\n",
    "    return Image.fromarray((x.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1726733127209,
     "user": {
      "displayName": "Hung Quang",
      "userId": "12748928474967436233"
     },
     "user_tz": -420
    },
    "id": "tlHnPpmo984j"
   },
   "outputs": [],
   "source": [
    "class SinusoidalEmbedding(nn.Module):\n",
    "    def __init__(self, time_steps, d_model):\n",
    "        super().__init__()\n",
    "        position = torch.arange(time_steps).unsqueeze(1).float()\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        self.embedding = torch.zeros(time_steps, d_model, requires_grad=False).to(device)\n",
    "        self.embedding[:, 0::2] = torch.sin(position * div)\n",
    "        self.embedding[:, 1::2] = torch.cos(position * div)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.embedding[t, None, None, :x.shape[3], None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTimeEmbedding(nn.Module):\n",
    "    def __init__(self, max_time_steps, embedding_dim, d_model):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(max_time_steps, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, d_model)\n",
    "        self.silu = nn.SiLU()\n",
    "        self.fc2 = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, t):\n",
    "        x = self.embedding(t)\n",
    "        x = self.fc1(x)\n",
    "        x = self.silu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Fh-dvyFjWywl"
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_groups, time_emb_dim=512, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.time_emb = nn.Linear(time_emb_dim, out_channels)\n",
    "        self.silu = nn.SiLU()\n",
    "        self.gnorm1 = nn.GroupNorm(num_groups=num_groups, num_channels=in_channels)\n",
    "        self.gnorm2 = nn.GroupNorm(num_groups=num_groups, num_channels=out_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob, inplace=True)\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        x = self.conv1(self.gnorm1(x))\n",
    "        r = x + self.time_emb(t_emb)[None, :, None, None]\n",
    "        r = self.dropout(r)\n",
    "        r = self.conv2(self.silu(self.gnorm2(r)))\n",
    "        return r + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlocks(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_groups, num_blocks=1, time_emb_dim=512, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([ResBlock(in_channels, out_channels, num_groups, dropout_prob=dropout_prob, time_emb_dim=time_emb_dim)])\n",
    "        for _ in range(num_blocks - 1):\n",
    "            self.blocks.append(ResBlock(out_channels, out_channels, num_groups, dropout_prob=dropout_prob, time_emb_dim=time_emb_dim))\n",
    "\n",
    "    def forward(self, x, t_emb):\n",
    "        for m in self.blocks:\n",
    "            x = m(x, t_emb)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_heads, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_channels = out_channels // num_heads\n",
    "        assert self.head_channels * self.num_heads == out_channels\n",
    "        \n",
    "        self.key = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.query = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.value = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv_out = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(p=dropout_prob, inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, channels, h, w = x.shape\n",
    "        query = self.query(x).view(batch, self.num_heads, self.head_channels, h * w)\n",
    "        key = self.key(x).view(batch, self.num_heads, self.head_channels, h * w).transpose(-1, -2)\n",
    "        value = self.value(x).view(batch, self.num_heads, self.head_channels, h, w)\n",
    "        \n",
    "        score = (query @ key) / (self.head_channels ** 0.5)\n",
    "        attention = F.softmax(score, dim=-1)\n",
    "        context = torch.einsum('bhcij,bhcc->bhcij', value, attention).view(batch, self.head_channels * self.num_heads, h, w)\n",
    "        x = self.dropout(context)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1726733127209,
     "user": {
      "displayName": "Hung Quang",
      "userId": "12748928474967436233"
     },
     "user_tz": -420
    },
    "id": "itBetN8wWCAM"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_blocks=2, num_heads=2, num_groups=32, dropout_prob=0.1, num_time_steps=1000, time_emb_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.time_embedding = LinearTimeEmbedding(num_time_steps, 128, time_emb_dim)\n",
    "        \n",
    "        self.downconv1 = nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.downconv2 = nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.downconv3 = nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.downconv4 = nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.downconv5 = nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.enc1 = ResBlocks(3, 128, 1, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "        self.enc2 = ResBlocks(128, 128, num_groups, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "        self.enc3 = ResBlocks(128, 256, num_groups, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "        self.enc4 = ResBlocks(256, 256, num_groups, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "        self.enc5 = ResBlocks(256, 512, num_groups, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "        \n",
    "        self.neck = ResBlocks(512, 512, num_groups, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(512, 512, 2, 2)\n",
    "        self.upconv2 = nn.ConvTranspose2d(512, 512, 2, 2)\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 256, 2, 2)\n",
    "        self.upconv4 = nn.ConvTranspose2d(256, 256, 2, 2)\n",
    "        self.upconv5 = nn.ConvTranspose2d(128, 128, 2, 2)\n",
    "\n",
    "        self.dec1 = ResBlocks(512 + 512, 512, num_groups, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "        self.dec2 = ResBlocks(512 + 256, 256, num_heads, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "        self.dec3 = ResBlocks(256 + 256, 256, num_heads, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "        self.dec4 = ResBlocks(256 + 128, 128, num_groups, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "        self.dec5 = ResBlocks(128 + 128, 128, num_groups, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "\n",
    "        self.cls_conv = ResBlocks(128, 3, 1, dropout_prob=dropout_prob, num_blocks=num_blocks, time_emb_dim=time_emb_dim)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_emb = self.time_embedding(t)\n",
    "        x = self.enc1(x, t_emb)\n",
    "        enc1 = x\n",
    "        x = self.downconv1(enc1)\n",
    "        x = self.enc2(x, t_emb)\n",
    "        enc2 = x\n",
    "        x = self.downconv2(enc2)\n",
    "        x = self.enc3(x, t_emb)\n",
    "        enc3 = x\n",
    "        x = self.downconv3(enc3)\n",
    "        x = self.enc4(x, t_emb)\n",
    "        enc4 = x\n",
    "        x = self.downconv4(enc4)\n",
    "        x = self.enc5(x, t_emb)\n",
    "        enc5 = x\n",
    "        x = self.downconv5(enc5)\n",
    "\n",
    "        x = self.neck(x, t_emb)\n",
    "\n",
    "        x = self.upconv1(x)\n",
    "        x = self.dec1(torch.cat((x, enc5), dim=1), t_emb)\n",
    "        x = self.upconv2(x)\n",
    "        x = self.dec2(torch.cat((x, enc4), dim=1), t_emb)\n",
    "        x = self.upconv3(x)\n",
    "        x = self.dec3(torch.cat((x, enc3), dim=1), t_emb)\n",
    "        x = self.upconv4(x)\n",
    "        x = self.dec4(torch.cat((x, enc2), dim=1), t_emb)\n",
    "        x = self.upconv5(x)\n",
    "        x = self.dec5(torch.cat((x, enc1), dim=1), t_emb)\n",
    "\n",
    "        x = self.cls_conv(x, t_emb)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1726733127209,
     "user": {
      "displayName": "Hung Quang",
      "userId": "12748928474967436233"
     },
     "user_tz": -420
    },
    "id": "oLj--_Ku5MDr"
   },
   "outputs": [],
   "source": [
    "class LinearNoiseSchedule():\n",
    "    def __init__(self, num_time_steps=1000):\n",
    "        self.beta = torch.linspace(1e-4, 0.02, num_time_steps, requires_grad=False).to(device)\n",
    "        alpha = 1 - self.beta\n",
    "        self.alpha = torch.cumprod(alpha, dim=0).requires_grad_(False).to(device)\n",
    "        self.sqrt_alpha = torch.sqrt(self.alpha).requires_grad_(False).to(device)\n",
    "        self.sqrt_beta = torch.sqrt(self.beta).requires_grad_(False).to(device)\n",
    "        self.sqrt_one_minus_beta = torch.sqrt(1 - self.beta).requires_grad_(False).to(device)\n",
    "        self.sqrt_one_minus_alpha = torch.sqrt(1 - self.alpha).requires_grad_(False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1726733127210,
     "user": {
      "displayName": "Hung Quang",
      "userId": "12748928474967436233"
     },
     "user_tz": -420
    },
    "id": "VEOcnh_rbca7"
   },
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, unet, noise_schedule):\n",
    "        super().__init__()\n",
    "        self.unet = unet\n",
    "        self.noise_schedule = noise_schedule\n",
    "\n",
    "    def forward(self, x, t, process='ddim', rand_factor=1.0):\n",
    "        return self.denoise(x, t, process=process, rand_factor=rand_factor)\n",
    "\n",
    "    def apply_noise(self, x, timesteps, process='ddpm'):\n",
    "        if type(timesteps) == int:\n",
    "            timesteps = torch.IntTensor([timesteps]).requires_grad_(False).to(x.device)\n",
    "        elif type(timesteps) == tuple or type(timesteps) == list:\n",
    "            timesteps = torch.IntTensor(timesteps).requires_grad_(False).to(x.device)\n",
    "        \n",
    "        noises = torch.randn(timesteps.shape[0], *x.shape).requires_grad_(False).to(x.device)\n",
    "        x = x * self.noise_schedule.sqrt_alpha[timesteps][:, None, None, None, None] + noises * self.noise_schedule.sqrt_one_minus_alpha[timesteps][:, None, None, None, None]\n",
    "        return x, noises\n",
    "\n",
    "    def denoise(self, x, timesteps, process='ddim', rand_factor=1.0)\n",
    "        if process == 'ddim':\n",
    "            return self.denoise_ddim(x, timesteps, rand_factor)\n",
    "        elif process = 'ddpm'\n",
    "            return self.denoise_ddpm(x, timesteps, rand_factor)\n",
    "    \n",
    "    def denoise_ddpm(self, x, timesteps, rand_factor=1.0):\n",
    "        e_pred = self.model(x, timesteps)\n",
    "        x0 = x - self.noise_schedule.sqrt_one_minus_alpha[timesteps] * e_pred\n",
    "        x0 = x0 * self.noise_schedule.sqrt_alpha[timesteps - 1] / self.noise_schedule.sqrt_alpha[timesteps]\n",
    "        xt_dir = torch.sqrt(self.noise_schedule.alpha[timesteps - 1] - self.noise_schedule.beta[timesteps])\n",
    "        xt_dir = xt_dir * e_pred\n",
    "        x = x0 + xt_dir + self.noise_schedule.sqrt_beta[timesteps] * torch.randn_like(x) * rand_factor\n",
    "        return x\n",
    "\n",
    "    def denoise_ddim(self, x, t, rand_factor=1.0):\n",
    "        e_pred = self.unet(x, t)\n",
    "        x = x - (self.noise_schedule.beta[t]) * e_pred / self.noise_schedule.sqrt_one_minus_alpha[t]\n",
    "        x = (x / self.noise_schedule.sqrt_one_minus_beta[t]) + self.noise_schedule.sqrt_beta[t] * torch.randn_like(x) * rand_factor\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(sample, denoise_steps=100, noise_step=100):\n",
    "    if denoise_steps is int:\n",
    "        denoise_steps = np.cos(np.linspace(0, np.pi / 2, num_steps)) * max_timesteps\n",
    "        denoise_steps = torch.tensor(denoise_steps, dtype=torch.int32)\n",
    "        denoise_steps = denoise_steps.unsqueeze(0).repeat(batch_size, 1).to(sample.device)\n",
    "    elif denoise_steps is list:\n",
    "        denoise_steps = torch.tensor(denoise_steps, dtype=torch.int32).to(sample.device)\n",
    "    elif denoise_steps is np.array:\n",
    "        denoise_steps = torch.from_numpy(denoise_steps).to(sample.device)\n",
    "    \n",
    "    sample = sample.to(device)\n",
    "    fig, axs = plt.subplots(1, (start_timestep - end_timestep) // print_gap + 2, figsize=(30, 3))\n",
    "    axs[0].imshow(to_pil_image(sample[0]))\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sample = diffusion_model.apply_noise(sample, noise_step)[0][0]\n",
    "    \n",
    "    axs[1].imshow(to_pil_image(sample[0]))\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    model.eval()\n",
    "    print_idx = 1\n",
    "    with torch.no_grad():\n",
    "        for t in denoise_steps:\n",
    "            sample = diffusion_model.denoise(sample, t)\n",
    "            if start_timestep - t >= print_gap * print_idx:\n",
    "                axs[print_idx + 1].imshow(to_pil_image(sample[0]))\n",
    "                axs[print_idx + 1].axis('off')\n",
    "                print_idx += 1\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_time_steps = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1726733527669,
     "user": {
      "displayName": "Hung Quang",
      "userId": "12748928474967436233"
     },
     "user_tz": -420
    },
    "id": "2ZptwjLw3WiQ"
   },
   "outputs": [],
   "source": [
    "model = UNet(num_time_steps=num_time_steps).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "noise_schedule = LinearNoiseSchedule(num_time_steps=num_time_steps)\n",
    "diffusion_model = DiffusionModel(model, noise_schedule).to(device)\n",
    "\n",
    "if os.path.isfile(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "    diffusion_model.load_state_dict(checkpoint['diffusion_model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foix1JmS-1IY",
    "outputId": "8eb995c3-b95d-41e8-abb4-2318fc619fce"
   },
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    optimizer.lr = args['lr']\n",
    "    epoch_per_pbar = args['epoch_per_pbar']\n",
    "    time_out_sec = args['time_out_sec']\n",
    "    time_out_epochs = args['time_out_epochs']\n",
    "\n",
    "    time_out_ep_count = 0\n",
    "    for ep in range(args['max_training_epochs'] // epoch_per_pbar):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "        with tqdm(total=epoch_per_pbar, desc=f'Epoch {ep * epoch_per_pbar + 1}-{(ep + 1) * epoch_per_pbar}/{args['max_training_epochs']}', unit=f'epoch', position=0, leave=True) as pbar_e:\n",
    "            for pbar_epoch in range(epoch_per_pbar):\n",
    "                for b, (img, _) in enumerate(dataloader):\n",
    "                    if args['timesteps'] == None:\n",
    "                        timesteps = torch.randint(1, num_time_steps, (1,)).to(device)\n",
    "                    else:\n",
    "                        timesteps = args['timesteps']\n",
    "                    img = img.to(device)\n",
    "                    imgs, noises = diffusion_model.apply_noise(img, timesteps)\n",
    "                    for noise, im, t in zip(noises, imgs, timesteps):\n",
    "                        optimizer.zero_grad()\n",
    "                        e_pred = model(im, t).sample\n",
    "                        # loss = criterion(e_pred, torch.randn_like(e_pred))\n",
    "                        loss = criterion(noise, e_pred)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        total_loss += loss.item()\n",
    "                        loss_count += 1\n",
    "                    pbar_e.set_postfix(loss=total_loss / loss_count)\n",
    "                pbar_e.update(1)\n",
    "                time_out_ep_count += 1\n",
    "                if time_out_ep_count >= time_out_epochs:\n",
    "                    time_out_ep_count = 0\n",
    "                    time.sleep(time_out_sec)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['max_training_epochs'] = 500\n",
    "args['epoch_per_pbar'] = 10\n",
    "args['lr'] = 1e-6\n",
    "args['timesteps'] = None\n",
    "args['time_out_sec'] = 60\n",
    "args['time_out_epochs'] = 1\n",
    "args['batch_size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1726733527669,
     "user": {
      "displayName": "Hung Quang",
      "userId": "12748928474967436233"
     },
     "user_tz": -420
    },
    "id": "0q5P1KINhuI6"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0, contrast=0, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomResizedCrop(size=(64, 64), scale=(0.8, 1)),\n",
    "    transforms.RandomRotation(15, fill=(1,)),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=img_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=args['batch_size'], shuffle=True, pin_memory=True)\n",
    "\n",
    "random_dataset = datasets.ImageFolder(root=random_img_path, transform=transform)\n",
    "random_dataloader = DataLoader(random_dataset, batch_size=args['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMfaT8b9IkE9"
   },
   "outputs": [],
   "source": [
    "diffusion_model.eval()\n",
    "sample = dataset[1][0].unsqueeze(0).to(device)\n",
    "out = generate(sample, noise_step=1500, start_timestep=1991, step_gap=1, print_gap=199)\n",
    "plt.imshow(to_pil_image(out[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[50][0].unsqueeze(0).to(device)\n",
    "generate(sample, noise_step=num_time_step-1, start_timestep=201, step_gap=5, print_gap=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = random_dataset[0][0].unsqueeze(0).to(device)\n",
    "generate(sample, noise_step=num_time_step-1, start_timestep=201, step_gap=10, print_gap=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(1, 3, 64, 64).to(device)\n",
    "generate(sample, noise_step=0, start_timestep=1000, step_gap=1, print_gap=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1726733298907,
     "user": {
      "displayName": "Hung Quang",
      "userId": "12748928474967436233"
     },
     "user_tz": -420
    },
    "id": "NbvZf6w_r8ma"
   },
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'diffusion_model': diffusion_model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "}\n",
    "torch.save(checkpoint, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
